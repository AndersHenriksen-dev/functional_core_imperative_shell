# User Guide

This guide explains how to run pipelines, how the architecture fits together, and how to extend the system safely.

## Design overview

The system is built around a few simple, composable concepts:

- **Contracts**: Pandera schemas define what inputs and outputs must look like.
- **Domain modules**: Each domain owns business logic and exposes a `run` function.
- **IO**: `read_dataframe` and `write_dataframe` handle registry-based IO.
- **Orchestration**: `run_domains` executes selected domains based on config.
- **Configuration**: Pydantic models validate Hydra configs into dataclasses.

This structure keeps pipelines readable and encourages SOLID principles:

- **Single Responsibility**: Domain modules own business logic; IO handles persistence.
- **Open/Closed**: New domains are added without editing core logic.
- **Dependency Injection**: IO and configuration can be overridden for tests.

The example domain reads silver inputs and produces gold outputs under [data/gold](../../data/gold).

## Configuration model

Hydra composes configuration from [configs](../../configs):

- [configs/config.yaml](../../configs/config.yaml) sets defaults and active filters.
- [configs/domains](../../configs/domains) defines per-domain inputs, outputs, and params.
- [configs/infrastructure](../../configs/infrastructure) defines logging.

The default config includes an example domain:

```yaml
# configs/domains/example_domain.yaml
example_domain:
  name: "Example Domain"
  enabled: true
  tags: ["daily"]
  params:
    score_threshold: 0.7
  inputs:
    customers:
      path: ${hydra:runtime.cwd}/data/silver/customers.csv
      format: csv
    transactions:
      path: ${hydra:runtime.cwd}/data/silver/transactions.csv
      format: csv
  outputs:
    scores:
      path: ${hydra:runtime.cwd}/data/gold/example_domain/scores.csv
      format: csv
    metrics:
      path: ${hydra:runtime.cwd}/data/gold/example_domain/metrics.csv
      format: csv
```

## IO and format options

The IO layer supports CSV, Parquet, JSON, Excel, Feather, ORC, Pickle, SQL, and Delta. Refer to the IO
formats guide for supported options and examples:

- [IO formats reference](io_formats.md)

## Running the pipelines

Run all configured domains:

```bash
python -m data_handling.main
```

Override values at runtime using Hydra syntax:

```bash
python -m data_handling.main domains.example_domain.outputs.scores.path="sales/custom_scores.csv"
python -m data_handling.main active_domains=[example_domain]
```

## Validation adapters

Validation happens inside domain logic with Pandera schemas. If you want to swap validation behavior, replace the Pandera decorators or add domain-level guards.

## Adding a new domain

Create a new domain module and wire it into configuration:

1. Add a module under `src/data_handling/domains/<domain>/pipeline.py`.
2. Implement a `run(cfg: DomainConfig)` function.
3. Define Pandera schemas under `src/data_handling/domains/<domain>/schemas.py`.
4. Add a domain config file under [configs/domains](../../configs/domains).
5. Update [configs/config.yaml](../../configs/config.yaml) defaults to include the new domain.

Minimal example for a new domain named `marketing`:

```python
from __future__ import annotations

from data_handling.core import read_dataframe, write_dataframe
from data_handling.core.logging import get_domain_logger
from data_handling.schema.types import DomainConfig


def run(cfg: DomainConfig) -> None:
    logger = get_domain_logger(__name__, cfg.name)

    sales = read_dataframe(cfg.inputs["sales"])
    summary = sales.groupby("region", as_index=False)["revenue"].sum()

    write_dataframe(summary, cfg.outputs["summary"])
    logger.info("Wrote %s rows", len(summary))
```

Config additions:

```yaml
# configs/domains/marketing.yaml
marketing:
  name: "Marketing"
  enabled: true
  tags: ["weekly"]
  inputs:
    sales:
      path: ${hydra:runtime.cwd}/data/silver/sales.csv
      format: csv
  outputs:
    summary:
      path: ${hydra:runtime.cwd}/data/gold/marketing/summary.csv
      format: csv
```

## How domains load

Domains are loaded dynamically from `data_handling.domains.<name>.pipeline`, and the `run` entry point is invoked. If a domain module is missing or does not export `run`, the orchestrator raises a domain error.

## Testing strategy

Tests mirror the package structure and validate both behavior and contracts:

- Unit tests for core utilities, errors, and IO behavior.
- Integration tests for domain pipelines.
- End-to-end tests that run `python -m data_handling.main` with real IO.

Run all tests:

```bash
python -m pytest -q
```

## Debugging tips

- Logs are written to `logs/` when file logging is enabled.
- Use `--cfg job` to inspect the full Hydra config.
- Keep pipeline logic small so failures are easy to isolate.

## Extension points

- Provide alternative readers/writers for custom storage backends.
- Swap config files with Hydra overrides for new environments.
- Add new domains by exporting a `run` function.
